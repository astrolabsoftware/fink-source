* DONE Reduce mem limit for pod journalnode !!!!
* Upgrade stackable operator to v2.1.0

* TODO hdfs operator

** limit and request for memory: see https://github.com/stackabletech/hdfs-operator/issues/625
** TODO: open issue: zkfc on datanode is not compliant with memory setting

In the example below memory limit is 256Mi for nameNode in hdfscluster CR, but it become 768Mi in each related pod because the `zkfs` container is not impacted by the CR configuration.
This should be fixed because it prevents running the setup on CI platforms with low memory like Github Action for instances.

kubectl get -n hdfs hdfscluster simple-hdfs  -o yaml -o jsonpath  -o=jsonpath='{.spec.nameNodes.config.resources}'
{"cpu":{"min":"0"},"memory":{"limit":"256Mi"}}

kubectl describe nodes | grep namenode
  hdfs                        simple-hdfs-namenode-default-0                                                         100m (0%)     1400m (1%)  768Mi (0%)       768Mi (0%)     34m
  hdfs                        simple-hdfs-namenode-default-1                                                         100m (0%)     1400m (1%)  768Mi (0%)       768Mi (0%)     31m

kubectl get pods -n hdfs simple-hdfs-namenode-default-0 -o jsonpath  -o=jsonpath='{.spec.containers[1].name}'
zkfc

kubectl get pods -n hdfs simple-hdfs-namenode-default-0 -o jsonpath  -o=jsonpath='{.spec.containers[1].resources}'  | jq
{
  "limits": {
    "cpu": "400m",
    "memory": "512Mi"
  },
  "requests": {
    "cpu": "100m",
    "memory": "512Mi"
  }
}


** management of argoCD default values (jqpath expression): https://github.com/stackabletech/hdfs-operator/issues/626
** TODO: open issue: be able to run only one dataNode on CI

* Add helm option on HDFS cpu.min (also for operators!)
* Move fink image to docker.stackable.tech/stackable/hadoop:3.3.6-stackable24.11.0
